
# Implementation Plan

This document outlines the steps for bringing the Tag Management System from specification to a running implementation.

## 1. Database Setup

**Objective:** Initialize and verify the PostgreSQL schema.

1. Run SQL build scripts inside the Postgres container.

	Example:

	```bash
	docker exec -it postgres_db psql -U postgres -d tag_management_system -f /scripts/schema.sql
	```

2. Verify schema integrity:

	```bash
	\dt
	\d+ table_name
	```

3. Optionally install **pgAdmin** or **Adminer** for visual inspection.

## 2. FastAPI Database Connection

**Objective:** Connect the autogenerated FastAPI service to Postgres.

1. Create a `.env` file:

	```txt
	DATABASE_URL=postgresql+psycopg2://postgres:password@postgres_db:5432/tag_management_system
	```

2. Configure SQLAlchemy or ORM to use `DATABASE_URL`.
3. Add a `/health/db` endpoint or startup event to check connectivity.

## 3. Seed and Validate Data

**Objective:** Populate initial records for testing.

Once the database containers are running, you can initialize the schema and load seed data directly from your local machine into the running PostgreSQL container using the **pipe-in method**. This method allows you to execute SQL files located on your host machine without needing to copy them into the container.

### General Command Syntax

```bash
docker exec -i <container_name> psql -U <username> -d <database> -f /path/inside/container/to/script.sql
```

Parameters

| Parameter            | Description                                                                                              |
| -------------------- | -------------------------------------------------------------------------------------------------------- |
| `postgres`           | The name of the running PostgreSQL container. **Replace this** with your actual container name if different. |
| `-U postgres`        | Specifies the database user to connect as.                                                               |
| `-d tag_management_system` | Specifies the database name to execute the script against.                                               |
| `< scripts/...`      | Pipes the contents of the local SQL file into the PostgreSQL process running inside the container.       |

### 3.1. Run Schema Initialization Script

Execute the following command to create all database tables, relationships, triggers, and constraints:

```bash
docker exec -i postgres psql -U postgres -d tag_management_system < scripts/00_schema_init.sql
```

### 3.2. Run Seed Data Script

After the schema is initialized, populate the database with sample lookup and reference data:

```bash
docker exec -i postgres psql -U postgres -d tag_management_system < scripts/01_seed_data.sql
```

### 3.3. Verify Schema and Data

After executing the scripts, you can verify that the tables and data were created correctly:

```bash
docker exec -it postgres psql -U postgres -d tag_management_system
```

Once inside the PostgreSQL shell, run the following commands:

```sql
\dt
SELECT * FROM tags;
SELECT * FROM entities;
```

This will confirm that the schema and seed data have been successfully loaded into your database.

## 4. API Validation

**Objective:** Ensure FastAPI endpoints are functional and aligned with the OpenAPI spec.

1. Start the API:

	```bash
	uvicorn app.main:app --reload
	```

2. Verify the interactive documentation at `http://localhost:8000/docs`.
3. Test all CRUD operations manually or using `curl`.
4. Compare `/openapi.json` output against `openapi.yaml`.

## 5. Testing and Schema Management

**Objective:** Prevent schema drift and verify endpoint behavior.

1. Implement `pytest` tests using `httpx.AsyncClient`.
2. Add migration management using **Alembic**.
3. Integrate schema validation tools to detect mismatches between ORM models and the database.

## 6. Containerization

**Objective:** Standardize environments through Docker Compose.

1. Define services in `docker-compose.yml`:

	* `postgres_db` (persistent volume)
	* `api` (FastAPI application)
	* `pgadmin` (optional)

2. Create environment-specific overrides:

	* `docker-compose.dev.yml` – local development
	* `docker-compose.test.yml` – CI testing
	* `docker-compose.prod.yml` – production deployment

3. Test connectivity from host:

	```bash
	curl http://localhost:8000/entities
	```

## 7. Logging and Observability

**Objective:** Enable consistent structured logging.

1. Integrate `structlog` or `loguru` for request-level logging.

	* Capture:

		* Request start/stop
		* Exceptions and SQL errors
		* Audit metadata (`created_by`, `updated_by`)

2. Optionally add Prometheus or OpenTelemetry metrics.

## 8. CI/CD and Deployment

**Objective:** Automate testing and builds.

* Create GitHub Actions workflows for:

	* Linting and formatting
	* Running tests
	* Building and pushing Docker images
	* Prepare Terraform configurations for deploying to AWS or hybrid clusters.

## 9. Documentation Synchronization

**Objective:** Keep documentation and implementation aligned.

1. Commit finalized `openapi.yaml`.
2. Add `docs/api/implementation.md` describing the spec-to-code workflow.
3. Optionally generate static documentation:

  ```bash
  npx redoc-cli bundle openapi.yaml -o docs/api.html
  ```

## 10. Next Milestone

**Objective:** Integrate with the routing and event middleware.

Once the Tag Management System is verified locally, integrate it with the Routing & Scheduling Middleware. This step will connect the Tag Management System to other microservices in the Data Management System ecosystem, such as the Image Processing System and Entity Management System.
